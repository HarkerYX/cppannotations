The template function hi(async)tt(std::async) potentially starts a new
thread. Once the function which is called by tt(async) terminates, the 
function's return value is made available in a tt(std::future) object
(cf. section ref(FUTURE)), with which it shares a shared state.

Before using the function tt(async) the tthi(future) header file must be
included. 

Two overloaded definitions of the function template tt(async) are available:
        verb(
    template <class Function, class ...Args>
    std::future<
        typename std::result_of<
                            Function(Args ...)
                 >::type
    > 
    std::async(Function &&fun, Args &&...args);
        )
and
        verb(
    template <class Function, class ...Args>
    std::future<typename std::result_of<Function(Args ...)>::type> 
        std::async(std::launch policy, Function &&fun, Args &&...args);
        )
    When calling these functions, the function tt(fun) and each of tt(fun)'s
arguments must be move-constructible. The first argument of the second
function is a value of the strongly typed enum 
    hi(deferred)hi(async)hi(launch)tt(std::launch):
        verb(
    enum class launch
    {
        async,
        deferred
    };
        )

The first tt(async) function is an abbreviated call for the second tt(async)
function, when passing it tt(launch::deferred) as its first argument.

Both functions create a shared state which can be obtained from the returned
tt(future) object.

The first tt(async) function and the second function, when
specifying tt(launch::deferred) call the function tt(fun). The returned
shared state is only available after the function tt(fun) has
returned.

However, when just calling tt(assign) it is likely that tt(fun) doesn't
return. The tt(launch::deferred) policy allows tt(async) to defer evaluation
until the implementation is ready for it, or the program explicitly asks for
it. Consider the following program:
        verbnrs(examples/async1.cc)
    Although tt(async) is called in line 14, when the program is run 
the output doesn't show tt(fun's) output line:
        verb(
    First async call starts
    First async call ends
    Second async call starts
    Second async call ends
        )
    This happens because of tt(lauch::deferred): the system simply defers
tt(fun's) execution until required, which never occurs. But the tt(future)
object that's returned by tt(async) has a member tt(wait). Once tt(wait)
returns the shred state must be available. In other words: tt(fun) must have
finished. Here is what happens when line 14 is changed into
tt(async(fun).wait()): 
        verb(
    First async call starts
        hello from fun
    First async call ends
    Second async call starts
        hello from fun
    Second async call ends
        )
    Evaluation of tt(fun) can thus be controlled to the point where we want
it, maybe even after calling tt(asyncCall), as shown in the next
example. Knowing that the function tt(fun) returns tt(void) 

    
    

    
                — if policy & launch::deferred is non-zero — Stores
            decay_copy(std::forward<F>(f)) and
            decay_copy(std::forward<Args>(args))... in the shared state. These
            copies of f and args constitute a deferred function. Invocation of
            the deferred function evaluates INVOKE (g, xyz) where g is the
            stored value of decay_copy(std::forward<F>(f)) and xyz is the
            stored copy of decay_copy(std::forward<Args>(args)).... The shared
            state is not made ready until the function has completed. 

The
            first call to a function requiring a non-timed wait on an
            asynchronous return object referring to the shared state created
            by this async call to become ready shall invoke the deferred
            function in the thread that called the waiting function; once
            evaluation of INVOKE (g, xyz) begins, the function is no longer
            considered deferred.
                Note: If this policy is specified together with other
            policies, such as when using a policy value of launch::async |
            launch::deferred, implementations should defer invocation or the
            selection of the policy when no more concurrency can be
            effectively exploited.

    The further behavior of the second
            function depends on the policy argument as follows (if more than
            one of these conditions applies, the implementation may choose any
            of the corresponding policies): 
                — if policy & launch::async is non-zero — executes INVOKE
            (decay_copy(std::forward<F>(f)),
            decay_copy(std::forward<Args>(args))...) (20.8.2, 30.3.1.2) as if
            in a new thread of execution represented by a thread object with
            the calls to decay_copy() being evaluated in the thread that
            called async. Any return value is stored as the result in the
            shared state. Any exception propagated from the execution of
            INVOKE (decay_copy(std::forward<F>(f)),
            decay_copy(std::forward<Args>(args))...) is stored as the
            exceptional result in the shared state. The thread object is
            stored in the shared state and affects the behavior of any
            asynchronous return objects that reference that state.




    Returns: An object of type future<typename result_of<F(Args...)>:type>
            that refers to the shared state created by this call to async. 
    Synchronization: Regardless of the provided policy argument,
            — the invocation of async synchronizes with (1.10) the invocation
                of f.  
                Note: This statement applies even when the corresponding future
                object is moved to another thread. 
        and
            — the completion of the function f is sequenced before (1.10) the
            shared state is made ready. 
                Note: f might not be called at all, so its completion might
                never happen.
        If policy & launch::async is non-zero,
            — a call to a waiting function on an asynchronous return object
            that shares the shared state created by this async call shall
            block until the associated thread has completed, as if joined
            (30.3.1.5); 
            — the join() on the created thread object synchronizes with (1.10)
            the return from the first function that successfully detects the
            ready status of the shared state or with the return from the last
            function that releases the shared state returns, whichever happens
            first. [Editor’s note: N3196 changes the following sentence as
            indicated. N3188 removes the sentence. Please pick one.] If the
            invocation is deferred, the completion of the invocation of the
            deferred function synchronizes with the successful return from a
            call to a waiting function on the shared state. 
    Throws: system_error if policy is launch::async and the implementation is
            unable to start a new thread. 
    Error conditions:
        — resource_unavailable_try_again — if policy is launch::async and the
            system is unable to start a new thread. 
    Remarks: The first signature shall not participate in overload resolution
            if decay<F>::type is std::launch. 
    Example:
        int work1(int value);
        int work2(int value);
        int work(int value) {
        auto handle = std::async([=]{ return work2(value); });
        int tmp = work1(value);
        return tmp + handle.get();
        // #1

    Note: Line #1 might not result in concurrency because the async call uses
            the default policy, which may use launch::deferred, in which case
            the lambda might not be invoked until the get() call; in that
            case, work1 and work2 are called on the same thread and there is
            no concurrency.  

